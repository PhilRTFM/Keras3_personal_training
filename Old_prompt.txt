R/models.R ‚Äî mod√®les MLP & Autoencodeur

mlp_build(input_dim, hidden_units = c(16L, 8L), activation = "relu", num_classes = 3L, lr = 1e-3, verbose = FALSE)
Entr√©es :
‚Ä¢ input_dim (int > 0) : nombre de variables d‚Äôentr√©e.
‚Ä¢ hidden_units (entiers) : tailles des couches cach√©es, ex. c(16L, 8L).
‚Ä¢ activation (chr) : activation des couches cach√©es (p.ex. "relu").
‚Ä¢ num_classes (int ‚â• 2) : nombre de classes (sortie softmax).
‚Ä¢ lr (num) : learning rate Adam.
‚Ä¢ verbose (logique) : messages.
Sortie : objet keras3::keras_model compil√© (loss="sparse_categorical_crossentropy", m√©trique sparse_categorical_accuracy), pr√™t pour keras3::fit().
I/O d‚Äôentra√Ænement attendus : x matrice/array num√©rique (n_obs √ó input_dim), y entiers dans [0..num_classes-1].

mlp_predict_labels(model, x, class_levels, verbose = FALSE)
Entr√©es :
‚Ä¢ model : mod√®le MLP entra√Æn√© (keras3::keras_model).
‚Ä¢ x : matrice/array de pr√©diction (n_obs √ó input_dim).
‚Ä¢ class_levels (chr, longueur K) : niveaux/ordre du softmax.
‚Ä¢ verbose (logique).
Sortie : factor des √©tiquettes pr√©dites (longueur n_obs, niveaux = class_levels).
D√©tails : calcule probs <- model(x) puis prend max.col pour l‚Äôargmax.

ae_build(input_dim, latent_dim = 2L, units = c(16L, 8L), activation = "relu", latent_activation = "linear", dropout = 0, batchnorm = FALSE, l2 = 0, lr = 1e-3, verbose = TRUE)
Entr√©es :
‚Ä¢ input_dim (int > 0), latent_dim (int ‚â• 1).
‚Ä¢ units (entiers) : tailles des couches encodeur (d√©codeur sym√©trique).
‚Ä¢ activation, latent_activation (chr).
‚Ä¢ dropout (num), batchnorm (logique), l2 (num), lr (num), verbose (logique).
Sortie : list(autoencoder, encoder, decoder) ‚Äî trois keras3::keras_model.
D√©tails : AE compil√© (loss="mse", m√©trique mae), t√¢che de reconstruction X ‚Üí X'. Donn√©es attendues pour l‚Äôentra√Ænement : x matrice num√©rique (n_obs √ó input_dim).

R/analysis.R ‚Äî PCA & MDS (avec graphiques)

pca_plot(x, dims = c(1, 2), group_factor = NULL, scale_unit = TRUE, ellipse = FALSE, ellipse_level = 0.95, verbose = FALSE)
Entr√©es :
‚Ä¢ x : data.frame|matrix num√©rique (lignes = individus).
‚Ä¢ dims (longueur 2) : composantes √† tracer.
‚Ä¢ group_factor (factor|NULL) : coloration des individus.
‚Ä¢ scale_unit (logique) : standardisation dans FactoMineR::PCA.
‚Ä¢ ellipse/ellipse_level : ellipses par groupe (optionnel).
‚Ä¢ verbose (logique).
Sortie : objet patchwork combinant 2 ggplot2 :

nuage d‚Äôindividus (axes + labels, ellipses √©ventuelles),

cercle des corr√©lations (cercle unit√© + fl√®ches variables).
Calcul : FactoMineR::PCA(as.data.frame(x), scale.unit = scale_unit, graph = FALSE).

mds_plot(x, method = "euclidean", metric = TRUE, k = 2, labels = NULL, group_factor = NULL, title = NULL, verbose = FALSE)
Entr√©es :
‚Ä¢ x : matrice|data.frame num√©rique (lignes = objets).
‚Ä¢ method (chr) : distance pour stats::dist (ex. "euclidean").
‚Ä¢ metric (logique) : MDS m√©trique (stats::cmdscale) vs non-m√©trique (MASS::isoMDS).
‚Ä¢ k (int) : dimension projet√©e (par d√©faut 2D).
‚Ä¢ labels (chr|NULL) : √©tiquettes des points.
‚Ä¢ group_factor (factor|NULL) : coloration.
‚Ä¢ title (chr|NULL), verbose (logique).
Sortie : patchwork de 2 ggplot2 :

scatter des coordonn√©es MDS (Dim.1 vs Dim.2),

diagramme de Shepard (distances originales vs projet√©es) avec RMSE et corr√©lation r affich√©s.

üìÇ R/metrics.R
1. viz_confusion_heatmap_sums(df_long, title = "Matrice de confusion", y_lab = "pr√©diction du mod√®le", core_pal = c("#cfe5f2", "#2b8cbe"), sum_pal = c("#a1d99b", "#31a354"), verbose = FALSE)

Entr√©es :
‚Ä¢ df_long (tibble) ‚Äî sortie d‚Äôune fonction interne cm_with_sums_long() (au format long, colonnes Truth, Pred, Freq, is_sum).
‚Ä¢ title (character) ‚Äî titre du graphique.
‚Ä¢ y_lab (character) ‚Äî libell√© de l‚Äôaxe Y.
‚Ä¢ core_pal, sum_pal (character(2)) ‚Äî palettes hex pour les cases centrales et les marges.
‚Ä¢ verbose (logical).

Sortie : ggplot2::ggplot ‚Äî heatmap de la matrice de confusion avec double gradient (centre vs marges).

D√©tails : distingue les cases c≈ìur (is_sum = FALSE) des sommes (is_sum = TRUE), normalise localement les couleurs.

2. metrics_table_plot(metrics_list, digits = 2, verbose = FALSE)

Entr√©es :
‚Ä¢ metrics_list (list) ‚Äî sortie de metrics_from_cm() ou metrics_build_from_cm() contenant au minimum accuracy et un tableau macro (macro_tbl ou macro).
‚Ä¢ digits (integer) ‚Äî nombre de d√©cimales.
‚Ä¢ verbose (logical).

Sortie : ggplot2::ggplot ‚Äî tableau stylis√© (gridExtra::tableGrob) encapsul√© en ggplot (via ggplotify::as.ggplot).

Colonnes typiques : Specificity, Sensitivity (recall), Accuracy, F1 score.

D√©tails : g√®re plusieurs conventions de noms (macro vs Macro, Recall vs macro_recall, etc.).

3. viz_confusion_panel_from_predictions(y_true, y_pred, labels = NULL, title = "Confusion Matrix (Test)", digits = 2L, show_bottomright = FALSE, verbose = FALSE)

Entr√©es :
‚Ä¢ y_true, y_pred (factor | character | integer) ‚Äî vecteurs de v√©rit√© terrain et pr√©dictions (longueur identique).
‚Ä¢ labels (character|NULL) ‚Äî niveaux/ordre des classes (sinon union tri√©e des valeurs).
‚Ä¢ title (character) ‚Äî titre global.
‚Ä¢ digits (integer) ‚Äî pr√©cision pour tableau m√©triques.
‚Ä¢ show_bottomright (logical) ‚Äî afficher ou non la somme globale dans la case (sum,sum).
‚Ä¢ verbose (logical).

Sortie : patchwork (2 lignes) :

heatmap (viz_confusion_heatmap_sums),

tableau macro (metrics_table_plot).

D√©tails :

Construit la matrice de confusion (table(Truth √ó Pred)), calcule TP/FP/FN/TN par classe.

G√©n√®re pr√©cision, rappel, sp√©cificit√©, F1 par classe.

Produit aussi agr√©gats macro (macro_precision, macro_recall, macro_f1, weighted_f1).

Cr√©e un df_long avec lignes/colonnes "sum" pour marges.

4. history_curves_plot(history, title = "Training curves", metrics = c("loss", "accuracy"), smooth = FALSE, verbose = FALSE)

Entr√©es :
‚Ä¢ history (list ou objet Python keras via reticulate) ‚Äî typiquement la sortie de keras3::fit().
‚Ä¢ title (character).
‚Ä¢ metrics (character) ‚Äî m√©triques √† tracer (par d√©faut c("loss", "accuracy")).
‚Ä¢ smooth (logical) ‚Äî applique un lissage LOESS (optionnel).
‚Ä¢ verbose (logical).

Sortie : ggplot2::ggplot ‚Äî courbes d‚Äôapprentissage facett√©es (loss et accuracy), avec couleurs distinctes train/validation.

D√©tails :

Compatibilit√© avec objets Python (history$history ‚Üí reticulate::py_to_r).

G√®re alias (sparse_categorical_accuracy ‚Üí accuracy).

Facettes s√©par√©es pour loss & accuracy.

Palette sobre (bleu pour loss, vert pour accuracy).



R/models.R ‚Äî mod√®les MLP & Autoencodeur

mlp_build(input_dim, hidden_units = c(16L, 8L), activation = "relu", num_classes = 3L, lr = 1e-3, verbose = FALSE)
Entr√©es :
‚Ä¢ input_dim (int > 0) : nombre de variables d‚Äôentr√©e.
‚Ä¢ hidden_units (entiers) : tailles des couches cach√©es, ex. c(16L, 8L).
‚Ä¢ activation (chr) : activation des couches cach√©es (p.ex. "relu").
‚Ä¢ num_classes (int ‚â• 2) : nombre de classes (sortie softmax).
‚Ä¢ lr (num) : learning rate Adam.
‚Ä¢ verbose (logique) : messages.
Sortie : objet keras3::keras_model compil√© (loss="sparse_categorical_crossentropy", m√©trique sparse_categorical_accuracy), pr√™t pour keras3::fit().
I/O d‚Äôentra√Ænement attendus : x matrice/array num√©rique (n_obs √ó input_dim), y entiers dans [0..num_classes-1].

mlp_predict_labels(model, x, class_levels, verbose = FALSE)
Entr√©es :
‚Ä¢ model : mod√®le MLP entra√Æn√© (keras3::keras_model).
‚Ä¢ x : matrice/array de pr√©diction (n_obs √ó input_dim).
‚Ä¢ class_levels (chr, longueur K) : niveaux/ordre du softmax.
‚Ä¢ verbose (logique).
Sortie : factor des √©tiquettes pr√©dites (longueur n_obs, niveaux = class_levels).
D√©tails : calcule probs <- model(x) puis prend max.col pour l‚Äôargmax.

ae_build(input_dim, latent_dim = 2L, units = c(16L, 8L), activation = "relu", latent_activation = "linear", dropout = 0, batchnorm = FALSE, l2 = 0, lr = 1e-3, verbose = TRUE)
Entr√©es :
‚Ä¢ input_dim (int > 0), latent_dim (int ‚â• 1).
‚Ä¢ units (entiers) : tailles des couches encodeur (d√©codeur sym√©trique).
‚Ä¢ activation, latent_activation (chr).
‚Ä¢ dropout (num), batchnorm (logique), l2 (num), lr (num), verbose (logique).
Sortie : list(autoencoder, encoder, decoder) ‚Äî trois keras3::keras_model.
D√©tails : AE compil√© (loss="mse", m√©trique mae), t√¢che de reconstruction X ‚Üí X'. Donn√©es attendues pour l‚Äôentra√Ænement : x matrice num√©rique (n_obs √ó input_dim).

R/analysis.R ‚Äî PCA & MDS (avec graphiques)

pca_plot(x, dims = c(1, 2), group_factor = NULL, scale_unit = TRUE, ellipse = FALSE, ellipse_level = 0.95, verbose = FALSE)
Entr√©es :
‚Ä¢ x : data.frame|matrix num√©rique (lignes = individus).
‚Ä¢ dims (longueur 2) : composantes √† tracer.
‚Ä¢ group_factor (factor|NULL) : coloration des individus.
‚Ä¢ scale_unit (logique) : standardisation dans FactoMineR::PCA.
‚Ä¢ ellipse/ellipse_level : ellipses par groupe (optionnel).
‚Ä¢ verbose (logique).
Sortie : objet patchwork combinant 2 ggplot2 :

nuage d‚Äôindividus (axes + labels, ellipses √©ventuelles),

cercle des corr√©lations (cercle unit√© + fl√®ches variables).
Calcul : FactoMineR::PCA(as.data.frame(x), scale.unit = scale_unit, graph = FALSE).

mds_plot(x, method = "euclidean", metric = TRUE, k = 2, labels = NULL, group_factor = NULL, title = NULL, verbose = FALSE)
Entr√©es :
‚Ä¢ x : matrice|data.frame num√©rique (lignes = objets).
‚Ä¢ method (chr) : distance pour stats::dist (ex. "euclidean").
‚Ä¢ metric (logique) : MDS m√©trique (stats::cmdscale) vs non-m√©trique (MASS::isoMDS).
‚Ä¢ k (int) : dimension projet√©e (par d√©faut 2D).
‚Ä¢ labels (chr|NULL) : √©tiquettes des points.
‚Ä¢ group_factor (factor|NULL) : coloration.
‚Ä¢ title (chr|NULL), verbose (logique).
Sortie : patchwork de 2 ggplot2 :

scatter des coordonn√©es MDS (Dim.1 vs Dim.2),

diagramme de Shepard (distances originales vs projet√©es) avec RMSE et corr√©lation r affich√©s.

üìÇ R/metrics.R
1. viz_confusion_heatmap_sums(df_long, title = "Matrice de confusion", y_lab = "pr√©diction du mod√®le", core_pal = c("#cfe5f2", "#2b8cbe"), sum_pal = c("#a1d99b", "#31a354"), verbose = FALSE)

Entr√©es :
‚Ä¢ df_long (tibble) ‚Äî sortie d‚Äôune fonction interne cm_with_sums_long() (au format long, colonnes Truth, Pred, Freq, is_sum).
‚Ä¢ title (character) ‚Äî titre du graphique.
‚Ä¢ y_lab (character) ‚Äî libell√© de l‚Äôaxe Y.
‚Ä¢ core_pal, sum_pal (character(2)) ‚Äî palettes hex pour les cases centrales et les marges.
‚Ä¢ verbose (logical).

Sortie : ggplot2::ggplot ‚Äî heatmap de la matrice de confusion avec double gradient (centre vs marges).

D√©tails : distingue les cases c≈ìur (is_sum = FALSE) des sommes (is_sum = TRUE), normalise localement les couleurs.

2. metrics_table_plot(metrics_list, digits = 2, verbose = FALSE)

Entr√©es :
‚Ä¢ metrics_list (list) ‚Äî sortie de metrics_from_cm() ou metrics_build_from_cm() contenant au minimum accuracy et un tableau macro (macro_tbl ou macro).
‚Ä¢ digits (integer) ‚Äî nombre de d√©cimales.
‚Ä¢ verbose (logical).

Sortie : ggplot2::ggplot ‚Äî tableau stylis√© (gridExtra::tableGrob) encapsul√© en ggplot (via ggplotify::as.ggplot).

Colonnes typiques : Specificity, Sensitivity (recall), Accuracy, F1 score.

D√©tails : g√®re plusieurs conventions de noms (macro vs Macro, Recall vs macro_recall, etc.).

3. viz_confusion_panel_from_predictions(y_true, y_pred, labels = NULL, title = "Confusion Matrix (Test)", digits = 2L, show_bottomright = FALSE, verbose = FALSE)

Entr√©es :
‚Ä¢ y_true, y_pred (factor | character | integer) ‚Äî vecteurs de v√©rit√© terrain et pr√©dictions (longueur identique).
‚Ä¢ labels (character|NULL) ‚Äî niveaux/ordre des classes (sinon union tri√©e des valeurs).
‚Ä¢ title (character) ‚Äî titre global.
‚Ä¢ digits (integer) ‚Äî pr√©cision pour tableau m√©triques.
‚Ä¢ show_bottomright (logical) ‚Äî afficher ou non la somme globale dans la case (sum,sum).
‚Ä¢ verbose (logical).

Sortie : patchwork (2 lignes) :

heatmap (viz_confusion_heatmap_sums),

tableau macro (metrics_table_plot).

D√©tails :

Construit la matrice de confusion (table(Truth √ó Pred)), calcule TP/FP/FN/TN par classe.

G√©n√®re pr√©cision, rappel, sp√©cificit√©, F1 par classe.

Produit aussi agr√©gats macro (macro_precision, macro_recall, macro_f1, weighted_f1).

Cr√©e un df_long avec lignes/colonnes "sum" pour marges.

4. history_curves_plot(history, title = "Training curves", metrics = c("loss", "accuracy"), smooth = FALSE, verbose = FALSE)

Entr√©es :
‚Ä¢ history (list ou objet Python keras via reticulate) ‚Äî typiquement la sortie de keras3::fit().
‚Ä¢ title (character).
‚Ä¢ metrics (character) ‚Äî m√©triques √† tracer (par d√©faut c("loss", "accuracy")).
‚Ä¢ smooth (logical) ‚Äî applique un lissage LOESS (optionnel).
‚Ä¢ verbose (logical).

Sortie : ggplot2::ggplot ‚Äî courbes d‚Äôapprentissage facett√©es (loss et accuracy), avec couleurs distinctes train/validation.

D√©tails :

Compatibilit√© avec objets Python (history$history ‚Üí reticulate::py_to_r).

G√®re alias (sparse_categorical_accuracy ‚Üí accuracy).

Facettes s√©par√©es pour loss & accuracy.

Palette sobre (bleu pour loss, vert pour accuracy).

je veux un script run_iris : 
- Ce script suppose que R/models.R, R/analysis.R et R/metrics.R existent.
- effectuer une MDS et une ACP sur Iris
- Pr√©pare le dataset iris pour utiliser le MLP et sortir une matrice de confusion et les graphiques associ√©s
- Pr√©pare le dataset iris pour utiliser l'Auto-encodeur et sortir une matrice de confusion et les graphiques associ√©s
- L'autoencodeur reconstruit IRIS, il faut effectuer MDS et ACP sur le IRIS reconstruit