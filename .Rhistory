#' @param prop numeric proportion train
#' @param seed integer graine
#' @param verbose logical
#' @return list (X_train, X_test, Y_train_bin, Y_test_bin, class_names, etc.)
prepare_iris_multilabel <- function(prop = 0.7,
seed = 123L,
verbose = FALSE) {
set.seed(seed)
data <- iris
class_names <- levels(data$Species)
# Créer un dataset altéré multi-label : ajouter aléatoirement une 2ème étiquette
n <- nrow(data)
multi_idx <- sample(seq_len(n), size = floor(0.1 * n))
Y <- lapply(as.character(data$Species), function(lbl) lbl)
for (i in multi_idx) {
extra <- sample(setdiff(class_names, data$Species[i]), 1)
Y[[i]] <- c(Y[[i]], extra)
}
# Binarisation des labels
Y_bin <- matrix(0L, nrow = n, ncol = length(class_names))
colnames(Y_bin) <- class_names
for (i in seq_len(n)) {
Y_bin[i, match(Y[[i]], class_names)] <- 1L
}
# Split train/test
idx <- stratified_split(factor(iris$Species), prop = prop, seed = seed)
X <- as.matrix(iris[, 1:4])
std <- standardize_train_test(X, idx$idx_train, idx$idx_test)
return(list(
X_raw = X,
Y_bin = Y_bin,
class_names = class_names,
idx_train = idx$idx_train,
idx_test = idx$idx_test,
X_train = std$x_train,
X_test  = std$x_test,
Y_train_bin = Y_bin[idx$idx_train, , drop = FALSE],
Y_test_bin  = Y_bin[idx$idx_test, , drop = FALSE]
))
}
#' Tableau descriptif IRIS multi-label
#' @param prep list sortie prepare_iris_multilabel
#' @return ggplotify::as.ggplot tableau descriptif
iris_multilabel_description <- function(prep) {
n_vars  <- ncol(prep$X_raw)
n_indiv <- nrow(prep$X_raw)
n_train <- length(prep$idx_train)
n_test  <- length(prep$idx_test)
df <- data.frame(
Variables = n_vars,
Individus = n_indiv,
Train = n_train,
Test = n_test
)
tbl <- gridExtra::tableGrob(df, rows = NULL,
theme = gridExtra::ttheme_minimal(
core = list(fg_params = list(fontface = 1)),
colhead = list(fg_params = list(fontface = 2),
bg_params = list(fill = "#e6e6e6"))))
return(ggplotify::as.ggplot(tbl))
}
# --- Pipeline complet --------------------------------------------------------
#' Analyse supervisée multi-label IRIS
#'
#' @param seed integer graine
#' @param verbose logical
#' @param auto_save logical Exporter PDF automatiquement
#' @return invisible(list(...)) Résultats
#' @export
run_iris_supervised_multilabel <- function(seed = 123L,
verbose = FALSE,
auto_save = TRUE) {
# Prétraitement
prep <- prepare_iris_multilabel(seed = seed, verbose = verbose)
# Page 1 : descriptif + heatmap co-occurrence
p_desc <- iris_multilabel_description(prep)
cooc <- crossprod(prep$Y_bin)
cooc_df <- as.data.frame(as.table(cooc))
cooc_df$Var1 <- factor(cooc_df$Var1, levels = prep$class_names)
cooc_df$Var2 <- factor(cooc_df$Var2, levels = prep$class_names)
p_cooc <- ggplot2::ggplot(cooc_df, ggplot2::aes(x = Var1, y = Var2, fill = Freq)) +
ggplot2::geom_tile(color = "white") +
ggplot2::geom_text(ggplot2::aes(label = Freq)) +
ggplot2::scale_fill_gradient(low = "#fee8c8", high = "#e34a33") +
ggplot2::theme_minimal() +
ggplot2::labs(title = "Co-occurrence des classes (IRIS alt)", x = NULL, y = NULL)
# Page 2 : MDS
p_mds <- mds_plot(prep$X_raw, group_factor = factor(iris$Species), verbose = verbose)
# Page 3 : PCA
p_pca <- pca_plot(prep$X_raw, group_factor = factor(iris$Species), verbose = verbose)
# Entraînement MLP multi-label
res_mlp <- train_mlp_multilabel_classifier(
prep$X_train, prep$Y_train_bin,
prep$X_test, prep$Y_test_bin,
build_args = list(),
fit_args = list(epochs = 50L, batch_size = 16L, validation_split = 0.2, verbose = ifelse(verbose, 1, 0)),
verbose = verbose
)
# Page 4 : Courbes d'entraînement (AUC, accuracy, loss)
p_history <- history_curves_plot(
res_mlp$history,
title = "Courbes entraînement MLP multi-label",
metrics = c("loss", "val_loss", "accuracy", "val_accuracy", "AUC", "val_AUC"),
verbose = verbose
)
# Page 5 : Confusions multi-label
preds_bin <- mlp_predict_multilabel(res_mlp$model, prep$X_test)
p_conf <- multilabel_confusion_heatmap(prep$Y_test_bin, preds_bin, prep$class_names)
# Page 6 : Tableau métriques
metrics <- multilabel_metrics(prep$Y_test_bin, preds_bin)
p_tbl <- metrics_table_multilabel(metrics)
# Préparer tous les plots
all_plots <- list(
p_desc,    # 1 descriptif
p_cooc,    # 1b co-occurrence
p_mds,     # 2 MDS
p_pca,     # 3 PCA
p_history, # 4 courbes entraînement
p_conf,    # 5 confusions multi-label
p_tbl      # 6 métriques
)
# Export PDF 16:9 unique
if (auto_save) {
out_dir <- "outputs_iris"
export_pdf_16x9(all_plots, out_dir, base_name = "iris_supervised_multilabel", verbose = verbose)
}
return(invisible(list(
prep = prep,
mlp  = res_mlp,
plots = all_plots,
metrics = metrics
)))
}
# --- Exécution si lancé directement -----------------------------------------
if (base::sys.nframe() == 0L) {
run_iris_supervised_multilabel(verbose = TRUE, auto_save = TRUE)
}
source("R/utils.R")
source("R/visualizations.R")
ls()  # pour voir les fonctions chargées
history_curves_plot
source("R/utils.R")
source("R/visualizations.R")
ls()  # pour voir les fonctions chargées
history_curves_plot
# -- inst/examples/iris_suppervised.R — Analyse supervisée IRIS ----------------
# --- Chargement des dépendances ----------------------------------------------
base::source("R/utils.R", chdir = TRUE)
base::source("R/suppervised_mod.R", chdir = TRUE)
base::source("R/visualizations.R", chdir = TRUE)
base::source("R/eval_sup.R", chdir = TRUE)
# --- Fixer la graine globale -------------------------------------------------
set_seed_global(123L)
# --- Helpers internes --------------------------------------------------------
#' Prépare les données iris
#' @param target character Colonne cible
#' @param prop numeric proportion train
#' @param seed integer graine
#' @param verbose logical
#' @return list (voir preprocess_data)
prepare_iris_data <- function(target = "Species",
prop = 0.7,
seed = 123L,
verbose = FALSE) {
return(preprocess_data(iris, target = target, prop = prop,
seed = seed, verbose = verbose))
}
#' Tableau descriptif IRIS
#' @param prep list sortie preprocess_data
#' @return ggplotify::as.ggplot tableau descriptif
iris_description_table <- function(prep) {
n_vars <- ncol(prep$X_raw)
n_indiv <- nrow(prep$X_raw)
n_train <- length(prep$idx_train)
n_test  <- length(prep$idx_test)
df <- data.frame(
Variables = n_vars,
Individus = n_indiv,
Train = n_train,
Test = n_test
)
tbl <- gridExtra::tableGrob(df, rows = NULL,
theme = gridExtra::ttheme_minimal(
core = list(fg_params = list(fontface = 1)),
colhead = list(fg_params = list(fontface = 2),
bg_params = list(fill = "#e6e6e6"))))
return(ggplotify::as.ggplot(tbl))
}
# --- Pipeline complet --------------------------------------------------------
#' Analyse supervisée IRIS
#'
#' @param seed integer graine
#' @param target character Colonne cible
#' @param verbose logical
#' @param auto_save logical Exporter PDF automatiquement
#' @return invisible(list(...)) Résultats
#' @export
run_iris_suppervised <- function(seed = 123L,
target = "Species",
verbose = FALSE,
auto_save = TRUE) {
# Prétraitement
prep <- prepare_iris_data(target = target, seed = seed, verbose = verbose)
# Page 1 : descriptif
p_desc <- iris_description_table(prep)
# Page 2 : MDS
p_mds <- mds_plot(prep$X_raw, group_factor = prep$y_fac, verbose = verbose)
# Page 3 : PCA
p_pca <- pca_plot(prep$X_raw, group_factor = prep$y_fac, verbose = verbose)
# Page 4-6 : Entraînement MLP
res_mlp <- train_mlp_classifier(
prep$X_train, prep$y_train_int,
prep$X_test, prep$y_test_fac,
prep$class_levels,
verbose = verbose
)
p_history_mlp <- history_curves_plot(res_mlp$history,
title = "Courbes entraînement MLP",
verbose = verbose)
# Confusion train
preds_train <- mlp_predict_labels(res_mlp$model, prep$X_train,
class_levels = prep$class_levels)
conf_train <- viz_confusion_panel_from_predictions(prep$y_train_fac,
preds_train,
labels = prep$class_levels,
title = "Confusion Matrix (Train)")
# Confusion test (déjà dans res_mlp)
conf_test <- res_mlp$confusion_plot
# Préparer tous les plots
all_plots <- list(
p_desc,         # Page 1
p_mds,          # Page 2
p_pca,          # Page 3
p_history_mlp,  # Page 4
conf_train,     # Page 5
conf_test       # Page 6
)
# Export PDF 16:9 unique
if (auto_save) {
out_dir <- "outputs_iris"
export_pdf_16x9(all_plots, out_dir, base_name = "iris_suppervised", verbose = verbose)
}
return(invisible(list(
prep = prep,
mlp = res_mlp,
plots = all_plots
)))
}
# --- Exécution si lancé directement -----------------------------------------
if (base::sys.nframe() == 0L) {
run_iris_suppervised(verbose = TRUE, auto_save = TRUE)
}
# -- inst/examples/iris_unsuppervised.R — Analyse non supervisée IRIS ---------
# --- Chargement des dépendances ----------------------------------------------
base::source("R/utils.R",            chdir = TRUE)
base::source("R/unsuppervised_mod.R",chdir = TRUE)
base::source("R/visualizations.R",   chdir = TRUE)
base::source("R/eval_unsup.R",       chdir = TRUE)
# --- Fixer la graine globale -------------------------------------------------
set_seed_global(123L)
# --- Helpers internes --------------------------------------------------------
#' Prépare les données iris
#' @param target character Colonne cible
#' @param prop numeric proportion train
#' @param seed integer graine
#' @param verbose logical
#' @return list (voir preprocess_data)
prepare_iris_data <- function(target = "Species",
prop = 0.7,
seed = 123L,
verbose = FALSE) {
return(preprocess_data(iris, target = target, prop = prop,
seed = seed, verbose = verbose))
}
# ... (reste du script inchangé) ...
#' Tableau descriptif IRIS
#' @param prep list sortie preprocess_data
#' @return ggplotify::as.ggplot tableau descriptif
iris_description_table <- function(prep) {
n_vars  <- ncol(prep$X_raw)
n_indiv <- nrow(prep$X_raw)
n_train <- length(prep$idx_train)
n_test  <- length(prep$idx_test)
df <- data.frame(
Variables = n_vars,
Individus = n_indiv,
Train = n_train,
Test = n_test
)
tbl <- gridExtra::tableGrob(df, rows = NULL,
theme = gridExtra::ttheme_minimal(
core = list(fg_params = list(fontface = 1)),
colhead = list(fg_params = list(fontface = 2),
bg_params = list(fill = "#e6e6e6"))))
return(ggplotify::as.ggplot(tbl))
}
# --- Pipeline complet --------------------------------------------------------
#' Analyse non supervisée IRIS (Autoencodeur)
#'
#' @param seed integer graine
#' @param target character Colonne cible
#' @param verbose logical
#' @param auto_save logical Exporter PDF automatiquement
#' @return invisible(list(...)) Résultats
#' @export
run_iris_unsuppervised <- function(seed = 123L,
target = "Species",
verbose = FALSE,
auto_save = TRUE) {
# Prétraitement
prep <- prepare_iris_data(target = target, seed = seed, verbose = verbose)
# Page 1 : descriptif
p_desc <- iris_description_table(prep)
# Page 2 : MDS (brut)
p_mds_raw <- mds_plot(prep$X_raw, group_factor = prep$y_fac, verbose = verbose)
# Page 3 : PCA (brut)
p_pca_raw <- pca_plot(prep$X_raw, group_factor = prep$y_fac, verbose = verbose)
# Entraînement Autoencodeur (sur split standardisé)
res_ae <- train_autoencoder(
prep$X_train, prep$X_test,
prep$y_train_fac, prep$y_test_fac,
prep$class_levels,
verbose = verbose
)
# Page 4 : Courbes d'entraînement AE
p_history_ae <- history_curves_plot(res_ae$history,
title = "Courbes entraînement AE",
metrics = c("loss"),
verbose = verbose)
# Page 5 : Shepard plot — distances originales (X_test) vs distances en 2D (MDS sur X_recon)
# NB: shepard_plot attend (dist_orig, coords_2D). On projette X_recon en 2D via cmdscale.
d_orig <- stats::dist(prep$X_test)
mds_recon <- stats::cmdscale(stats::dist(res_ae$X_recon), k = 2, eig = TRUE)
coords_recon_2d <- as.matrix(mds_recon$points)
colnames(coords_recon_2d) <- c("Dim1","Dim2")
p_shepard <- shepard_plot(d_orig, coords_recon_2d, method = "pearson", verbose = verbose)
# Page 6 : MDS sur X_recon (plot déjà fourni dans res_ae)
p_mds_recon <- res_ae$mds_plot
# Page 7 : PCA sur X_recon (plot déjà fourni dans res_ae)
p_pca_recon <- res_ae$pca_plot
# Préparer tous les plots dans l'ordre voulu
all_plots <- list(
p_desc,        # 1
p_mds_raw,     # 2
p_pca_raw,     # 3
p_history_ae,  # 4
p_shepard,     # 5
p_mds_recon,   # 6
p_pca_recon    # 7
)
# Export PDF 16:9 unique
if (auto_save) {
out_dir <- "outputs_iris"
export_pdf_16x9(all_plots, out_dir, base_name = "iris_unsuppervised", verbose = verbose)
}
return(invisible(list(
prep = prep,
ae   = res_ae,
plots = all_plots
)))
}
# --- Exécution si lancé directement -----------------------------------------
if (base::sys.nframe() == 0L) {
run_iris_unsuppervised(verbose = TRUE, auto_save = TRUE)
}
# -- inst/examples/iris_supervised_multilabel.R -------------------------------
# --- Chargement des dépendances ----------------------------------------------
base::source("R/utils.R",                  chdir = TRUE)
base::source("R/supervised_mod_multilabel.R", chdir = TRUE)
base::source("R/visualizations.R",         chdir = TRUE)
base::source("R/eval_multi_label.R",       chdir = TRUE)
# --- Fixer la graine globale -------------------------------------------------
set_seed_global(123L)
# --- Helpers internes --------------------------------------------------------
#' Prépare les données iris multi-label
#' @param prop numeric proportion train
#' @param seed integer graine
#' @param verbose logical
#' @return list (X_train, X_test, Y_train_bin, Y_test_bin, class_names, etc.)
prepare_iris_multilabel <- function(prop = 0.7,
seed = 123L,
verbose = FALSE) {
set.seed(seed)
data <- iris
class_names <- levels(data$Species)
# Créer un dataset altéré multi-label : ajouter aléatoirement une 2ème étiquette
n <- nrow(data)
multi_idx <- sample(seq_len(n), size = floor(0.1 * n))
Y <- lapply(as.character(data$Species), function(lbl) lbl)
for (i in multi_idx) {
extra <- sample(setdiff(class_names, data$Species[i]), 1)
Y[[i]] <- c(Y[[i]], extra)
}
# Binarisation des labels
Y_bin <- matrix(0L, nrow = n, ncol = length(class_names))
colnames(Y_bin) <- class_names
for (i in seq_len(n)) {
Y_bin[i, match(Y[[i]], class_names)] <- 1L
}
# Split train/test
idx <- stratified_split(factor(iris$Species), prop = prop, seed = seed)
X <- as.matrix(iris[, 1:4])
std <- standardize_train_test(X, idx$idx_train, idx$idx_test)
return(list(
X_raw = X,
Y_bin = Y_bin,
class_names = class_names,
idx_train = idx$idx_train,
idx_test = idx$idx_test,
X_train = std$x_train,
X_test  = std$x_test,
Y_train_bin = Y_bin[idx$idx_train, , drop = FALSE],
Y_test_bin  = Y_bin[idx$idx_test, , drop = FALSE]
))
}
#' Tableau descriptif IRIS multi-label
#' @param prep list sortie prepare_iris_multilabel
#' @return ggplotify::as.ggplot tableau descriptif
iris_multilabel_description <- function(prep) {
n_vars  <- ncol(prep$X_raw)
n_indiv <- nrow(prep$X_raw)
n_train <- length(prep$idx_train)
n_test  <- length(prep$idx_test)
df <- data.frame(
Variables = n_vars,
Individus = n_indiv,
Train = n_train,
Test = n_test
)
tbl <- gridExtra::tableGrob(df, rows = NULL,
theme = gridExtra::ttheme_minimal(
core = list(fg_params = list(fontface = 1)),
colhead = list(fg_params = list(fontface = 2),
bg_params = list(fill = "#e6e6e6"))))
return(ggplotify::as.ggplot(tbl))
}
# --- Pipeline complet --------------------------------------------------------
#' Analyse supervisée multi-label IRIS
#'
#' @param seed integer graine
#' @param verbose logical
#' @param auto_save logical Exporter PDF automatiquement
#' @return invisible(list(...)) Résultats
#' @export
run_iris_supervised_multilabel <- function(seed = 123L,
verbose = FALSE,
auto_save = TRUE) {
# Prétraitement
prep <- prepare_iris_multilabel(seed = seed, verbose = verbose)
# Page 1 : descriptif + heatmap co-occurrence
p_desc <- iris_multilabel_description(prep)
cooc <- crossprod(prep$Y_bin)
cooc_df <- as.data.frame(as.table(cooc))
cooc_df$Var1 <- factor(cooc_df$Var1, levels = prep$class_names)
cooc_df$Var2 <- factor(cooc_df$Var2, levels = prep$class_names)
p_cooc <- ggplot2::ggplot(cooc_df, ggplot2::aes(x = Var1, y = Var2, fill = Freq)) +
ggplot2::geom_tile(color = "white") +
ggplot2::geom_text(ggplot2::aes(label = Freq)) +
ggplot2::scale_fill_gradient(low = "#fee8c8", high = "#e34a33") +
ggplot2::theme_minimal() +
ggplot2::labs(title = "Co-occurrence des classes (IRIS alt)", x = NULL, y = NULL)
# Page 2 : MDS
p_mds <- mds_plot(prep$X_raw, group_factor = factor(iris$Species), verbose = verbose)
# Page 3 : PCA
p_pca <- pca_plot(prep$X_raw, group_factor = factor(iris$Species), verbose = verbose)
# Entraînement MLP multi-label
res_mlp <- train_mlp_multilabel_classifier(
prep$X_train, prep$Y_train_bin,
prep$X_test, prep$Y_test_bin,
build_args = list(),
fit_args = list(epochs = 50L, batch_size = 16L, validation_split = 0.2, verbose = ifelse(verbose, 1, 0)),
verbose = verbose
)
# Page 4 : Courbes d'entraînement (loss, accuracy, AUC)
p_history <- history_curves_plot(
res_mlp$history,
title = "Courbes entraînement MLP multi-label",
metrics = c("loss", "accuracy", "AUC"),
verbose = verbose
)
# Page 5 : Confusions multi-label
preds_bin <- mlp_predict_multilabel(res_mlp$model, prep$X_test)
p_conf <- multilabel_confusion_heatmap(prep$Y_test_bin, preds_bin, prep$class_names)
# Page 6 : Tableau métriques
metrics <- multilabel_metrics(prep$Y_test_bin, preds_bin)
p_tbl <- metrics_table_multilabel(metrics)
# Préparer tous les plots
all_plots <- list(
p_desc,    # 1 descriptif
p_cooc,    # 1b co-occurrence
p_mds,     # 2 MDS
p_pca,     # 3 PCA
p_history, # 4 courbes entraînement
p_conf,    # 5 confusions multi-label
p_tbl      # 6 métriques
)
# Export PDF 16:9 unique
if (auto_save) {
out_dir <- "outputs_iris"
export_pdf_16x9(all_plots, out_dir, base_name = "iris_supervised_multilabel", verbose = verbose)
}
return(invisible(list(
prep = prep,
mlp  = res_mlp,
plots = all_plots,
metrics = metrics
)))
}
# --- Exécution si lancé directement -----------------------------------------
if (base::sys.nframe() == 0L) {
run_iris_supervised_multilabel(verbose = TRUE, auto_save = TRUE)
}
